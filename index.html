<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.4.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Jing Li">

  
  
  
    
  
  <meta name="description" content="Eduardo D. Glandt Faculty Fellow and Associate Professor">

  
  <link rel="alternate" hreflang="en-us" href="https://penn-cil.github.io/">

  


  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono&display=swap">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.7c75abe867d1ac4b26fbe501f37ef260.css">

  
    
    
    
    
      
    
    
    
    <link rel="stylesheet" href="/css/academic.c271459694f356ca716e4e62b3b71072.css">
  

  
  
  

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Penn Computational Intelligence Lab">
  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon-32.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://penn-cil.github.io/">

  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Penn Computational Intelligence Lab">
  <meta property="og:url" content="https://penn-cil.github.io/">
  <meta property="og:title" content="Penn Computational Intelligence Lab">
  <meta property="og:description" content="Eduardo D. Glandt Faculty Fellow and Associate Professor"><meta property="og:image" content="https://penn-cil.github.io/img/logo.png">
  <meta property="twitter:image" content="https://penn-cil.github.io/img/logo.png"><meta property="og:locale" content="en-us">
  
    <meta property="og:updated_time" content="2019-08-10T00:00:00&#43;00:00">
  

  


  





  <title>Penn Computational Intelligence Lab</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#navbar-main" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0 compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/"><img src="/img/logo.png" alt="Penn Computational Intelligence Lab"></a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#top" data-target="#top"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts" data-target="#posts"><span>News</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about" data-target="#about"><span>PI</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#people" data-target="#people"><span>The Lab</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#research" data-target="#research"><span>Research</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects" data-target="#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications" data-target="#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#talks" data-target="#talks"><span>Talks</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/courses/"><span>Courses</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#sponsors" data-target="#sponsors"><span>Sponsors</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact" data-target="#contact"><span>Contact & Openings</span></a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>


  


<span class="js-widget-page d-none"></span>




  







  
  
  

  

  

  
    
    
      
    
    
    
  

  
    
    
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="top" class="home-section wg-blank dark parallax " style="background-image: linear-gradient(rgba(0, 0, 0, 0.6), rgba(0, 0, 0, 0.6)), url(&#39;https://penn-cil.github.io/img/bg-temp-1024x832.jpg&#39;);padding: 20px 0 20px 0;" >
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      <h1>Penn Computational Intelligence Lab (PennCIL)</h1>
      <p><em>Research into noval solutions to complex computing problems</em></p>
      <p>At Penn Computational Intelligence Lab (<strong>PennCIL</strong>), we are exploring non-conventional computing paradigms beyond Von Neumann computing, to make future computer systems more intelligent, performant, robust, and secure.</p>
<p>We are broadly interested in the big problems in computer system across the full stack. For that, our research spans device, VLSI, design automation, computer architecture and related system support (OS/PL/VM), and algorithm. One key differentiator of our research is that besides modeling and simulations, we put strong emphasis on <em>real hardware</em> demonstration through architecting, designing and testing new prototypes, both at <em>chip</em> level and <em>system</em> level to validate our theory. In addition to hardware, we are also interested in bringing up ecosystems and developing key software instrastrucutre to support the new hardware. The systems that we built have achieved several key milestones. One of the highlights is <strong>ENIAD</strong>, a successor to <a href="https://en.wikipedia.org/wiki/ENIAC">ENIAC</a>, which is ranked <strong>No. 1</strong> on <a href="https://graph500.org/?page_id=946">GreenGraph500 list</a> and sets the world record performance in AI-enriched big data analytics (e.g., cognitive search - the next generation search engine). To further extend the system scaling roadmap beyond Moore&rsquo;s law, we have taped out several new computer chips with <em>complete system</em> support (programming model, runtime, virtualization, API, etc.) that are built with post-CMOS nonvolatile memory technology (e.g., RRAM) integrated with silicon CMOS through monolithic 3D integration, including Liquid Silicon which won <strong>DARPA Young Faculty Award</strong> (one out of 2 in computer area and one out of 26 across all areas in science and technology nationwide), and Two-Dimensional Associative Processor (2D AP) which won <strong>NSF CAREER Award</strong>, in addition to the <em>first</em> fabricated in-memory processing chip for search, and a variable-bit storage chip which won IBM&rsquo;s the highest technical achievement awards, <strong>the IBM&rsquo;s CEO Milestone</strong>. More details about our research can be found at <a href="#research">Research</a>. A research vision on the importance of interaction between machine learning and computer system can be found at our <a href="https://arxiv.org/abs/1904.03257">white paper</a> (co-authored with a number of experts in both machine learning and system fields). A research vision on future memory and storage can be found at our <a href="https://www.youtube.com/watch?v=67VKORQX4T4">SRC-SIA Webinar Decadal Plan for Semiconductors: New Trajectories for Memory and Storage</a> with Dr. Sean Eilert (Micron), Dr. Carolyn Duran (Intel), Dr. David Pellerin (Amazon), Dr. Steffen Hellmold (Twist Bioscience), Dr. Jesse Mee (Air Force Research Laboratory), moderated by Dr. Heike Riel (IBM).</p>
<p>PennCIL is associated with the <a href="https://www.ese.upenn.edu/">ESE department</a> and the <a href="https://www.cis.upenn.edu/">CIS department</a> at the University of Pennsylvania. We were part of <a href="http://pages.cs.wisc.edu/~arch/uwarch/">Computer Architecture group</a> and <a href="https://machinelearning.wisc.edu/">Machine Learning group</a> at UW-Madison.</p>
<p>We are also part of one of the six SRC JUMP centers - Center for Research on Intelligent Storage and Processing-In-Memory (<a href="https://crisp.engineering.virginia.edu/staff">CRISP</a>).</p>
<p>Our research also greatly benefits from our strong ties with the leading industry and successful technology transfer experience. We would like to thank <a href="#sponsors">our sponsors</a>.</p>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="posts" class="home-section wg-pages   "  >
    <div class="container">
      








  























  





  


<div class="row">
  <div class="col-12 col-lg-4 section-heading">
    <h1>Recent News</h1>
    
  </div>
  <div class="col-12 col-lg-8">

    

    
      
        










  





  


<div class="media stream-item" itemscope itemtype="http://schema.org/BlogPosting">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0" itemprop="name">
      <a href="/post/src-sia-webnar/"  itemprop="url">Honored to join the Roundtable SRC-SIA Webinar Decadal Plan for Semiconductors: New Trajectories for Memory and Storage</a>
    </h3>

    
    <div class="article-style" itemprop="articleBody">
      With Dr. Sean Eilert (Micron), Dr. Carolyn Duran (Intel), Dr. David Pellerin (Amazon), Dr. Steffen Hellmold (Twist Bioscience), Dr. …
    </div>
    

    <div class="stream-meta article-metadata">

      

      
        



<meta content="2021-12-09 11:44:36 -0500 EST" itemprop="datePublished">
<meta content="2021-12-09 11:44:36 -0500 EST" itemprop="dateModified">

<div class="article-metadata">

  
  
  
  
  <div>
    



  <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/jing-li/">Jing Li</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    <time>Dec 9, 2021</time>
  </span>
  

  

  

  
  
  

  
  

  

</div>

      
    </div>

    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/post/src-sia-webnar/" >
      <img src="/post/src-sia-webnar/featured_huf1ac96f922ac59ba3e2ccc6ab6131daf_873884_150x0_resize_lanczos_2.png" itemprop="image">
    </a>
    
  </div>
</div>

      
    
      
        










  





  


<div class="media stream-item" itemscope itemtype="http://schema.org/BlogPosting">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0" itemprop="name">
      <a href="/post/penntoday2021/"  itemprop="url">ENIAD is on PennToday!</a>
    </h3>

    
    <div class="article-style" itemprop="articleBody">
      Penn Engineering’s ENIAD sets new world record for energy-efficient supercomputing
    </div>
    

    <div class="stream-meta article-metadata">

      

      
        



<meta content="2021-08-11 11:44:36 -0500 -0500" itemprop="datePublished">
<meta content="2021-08-11 11:44:36 -0500 -0500" itemprop="dateModified">

<div class="article-metadata">

  
  
  
  
  <div>
    



  <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/jialiang-zhang/">Jialiang Zhang</a></span>, <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/jing-li/">Jing Li</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    <time>Aug 11, 2021</time>
  </span>
  

  

  

  
  
  

  
  

  

</div>

      
    </div>

    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

      
    
      
        










  





  


<div class="media stream-item" itemscope itemtype="http://schema.org/BlogPosting">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0" itemprop="name">
      <a href="/post/greengraph500-2021/"  itemprop="url">Our supercomputer ranked No. 1 in the world!</a>
    </h3>

    
    <div class="article-style" itemprop="articleBody">
      Our ENIAD is ranked No. 1 on the latest GreenGraph500 list. Congrats to Jialiang!
    </div>
    

    <div class="stream-meta article-metadata">

      

      
        



<meta content="2021-07-05 11:44:36 -0500 -0500" itemprop="datePublished">
<meta content="2021-07-05 11:44:36 -0500 -0500" itemprop="dateModified">

<div class="article-metadata">

  
  
  
  
  <div>
    



  <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/jialiang-zhang/">Jialiang Zhang</a></span>, <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/jing-li/">Jing Li</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    <time>Jul 5, 2021</time>
  </span>
  

  

  

  
  
  

  
  

  

</div>

      
    </div>

    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/post/greengraph500-2021/" >
      <img src="/post/greengraph500-2021/featured_huc73d9a761e394388bf0c5e142aeb05ec_306126_150x0_resize_lanczos_2.png" itemprop="image">
    </a>
    
  </div>
</div>

      
    

    
    <div class="see-all">
      <a href="/post/">
        See all posts
        <i class="fas fa-angle-right"></i>
      </a>
    </div>
    

  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="about" class="home-section wg-about   "  >
    <div class="container">
      




  









<div class="row" itemprop="author" itemscope itemtype="http://schema.org/Person" itemref="person-email person-address">
  <div class="col-12 col-lg-4">
    <div id="profile">

      
      
      <img class="portrait" src="/authors/jing-li/avatar_hu0790a3ba0716acc2a92d0803f484434f_59031_250x250_fill_q90_lanczos_center.jpg" itemprop="image" alt="Avatar">
      

      <div class="portrait-title">
        <h2 itemprop="name">Jing Li</h2>
        <h3 itemprop="jobTitle">Eduardo D. Glandt Faculty Fellow and Associate Professor</h3>

        
        <h3 itemprop="worksFor" itemscope itemtype="http://schema.org/Organization">
          <a href="https://www.ese.upenn.edu/" target="_blank" itemprop="url" rel="noopener">
          <span itemprop="name">Department of Electrical and System Engineering</span>
          </a>
        </h3>
        
        <h3 itemprop="worksFor" itemscope itemtype="http://schema.org/Organization">
          <a href="https://www.cis.upenn.edu/" target="_blank" itemprop="url" rel="noopener">
          <span itemprop="name">Department of Computer and Information Science</span>
          </a>
        </h3>
        
        <h3 itemprop="worksFor" itemscope itemtype="http://schema.org/Organization">
          <a href="https://home.www.upenn.edu/" target="_blank" itemprop="url" rel="noopener">
          <span itemprop="name">University of Pennsylvania</span>
          </a>
        </h3>
        
      </div>

      <link itemprop="url" href="">

      <ul class="network-icon" aria-hidden="true">
        
        
        
        
          
        
        
        
        
        
        <li>
          <a itemprop="sameAs" href="mailto:janeli%20@%20seas.upenn.edu" >
            <i class="fas fa-envelope big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a itemprop="sameAs" href="https://twitter.com/jing_jane_li" target="_blank" rel="noopener">
            <i class="fab fa-twitter big-icon"></i>
          </a>
        </li>
        
        
        
        
        
        
        
        
          
        
        <li>
          <a itemprop="sameAs" href="https://scholar.google.com/citations?hl=en&amp;authuser=2&amp;user=QGYL3tAAAAAJ" target="_blank" rel="noopener">
            <i class="ai ai-google-scholar big-icon"></i>
          </a>
        </li>
        
        
        
        
        
        
        
        
          
        
        <li>
          <a itemprop="sameAs" href="/files/CV_JingLi.pdf" >
            <i class="ai ai-cv big-icon"></i>
          </a>
        </li>
        
      </ul>

    </div>
  </div>
  <div class="col-12 col-lg-8" itemprop="description">

    
    <h1>Principal Investigator</h1>

    <p>Dr. Jing (Jane) Li is the Eduardo D. Glandt Faculty Fellow and Associate Professor (with tenure) at the Department of Electrical and System Engineering and the Department of Computer and Information Science at the University of Pennsylvania. Previously she was the Dugald C. Jackson Assistant Professor at the University of Wisconsin–Madison and a faculty affiliate with the UW-Madison <a href="http://pages.cs.wisc.edu/~arch/uwarch/">Computer Architecture group</a> and <a href="https://machinelearning.wisc.edu/">Machine Learning group</a>. She is one of the PIs in SRC JUMP center – Center for Research on Intelligent Storage and Processing-In-Memory (<a href="https://crisp.engineering.virginia.edu/staff">CRISP</a>). She spent her early career at <a href="https://www.research.ibm.com/labs/watson/">IBM T. J. Watson Research Center</a> as a <em>Research Staff Member</em> after obtaining her PhD degree from Purdue University in 2009.</p>
<p>She is attracted to <em>all the big problems</em> she can find in computer system across the stack regardless the specific sub-areas. She is a passionate <strong>computer experimentalist</strong> and enjoy building <em>real</em> computer systems (both hardware and software). She has made contributions to the following &ldquo;<em>memory-centric</em>&rdquo; areas: 1) domain-specific accelerator and its interaction with emerging memories (HMC/HBM/NVM), 2) programmable in-memory computing architecture enabled by emerging nonvolatile memories (PCM/RRAM), 3) system support (e.g., virtualization) for accelerators (e.g., FPGA), and 4) FPGA-based full system simulation infrastructure (MEG) for memory system research. She has strong ties with leading technology companies and has successful technology transfer experience (<strong>&gt;40 issued/pending patents</strong>).</p>
<p>She is the recipient of prestigious <strong>NSF Career Award</strong> in 2018, <strong>DARPA&rsquo;s Young Faculty Award</strong> (<em>one out of 2 in computer area and one out of 26 across all areas in science and technology nationwide, the first awardee in computer engineering and computer science at UW-Madison</em>) in 2016, WARF Innovation Awards (WIA) Finalist (only 6 patented technologies out of 400+ patents got selected university wide), <strong>IBM Research Division Outstanding Technical Achievement Award</strong> in 2012 for successfully achieving <strong>CEO milestone</strong>, multiple invention achievement awards and high value patent application awards from IBM from 2010-2014, IBM Ph.D. Fellowship Award in 2008, Meissner Fellowship in 2004 from Purdue University, etc. Her research was reported by <a href="https://ca.news.yahoo.com/liquid-silicon-chips-could-integrate-010242640.html">Yahoo News</a>, <a href="https://www.neweggbusiness.com/smartbuyer/components/liquid-silicon-computer-hardware/">Newegg Business</a>, <a href="https://www.digitaltrends.com/computing/liquid-silicon-merge-hardware-software-one-device/">Digital Trends</a>, etc. And she was featured in Madison Magazine (Channel 3000) as a <a href="https://www.channel3000.com/madison-magazine/city-life/a-rising-research-star/524062115">rising research star</a>.</p>
<p>She has been serving on the technical committee for the ACM International Conference on Architectural Support for Programming Languages and Operating Systems (<strong>ASPLOS</strong>), International Symposium on Computer Architecture (<strong>ISCA</strong>) (both regular and industry tracks), Machine Learning and Systems (<strong>MLSys</strong>), International Conference for High Performance Computing, Networking, Storage, and Analysis (<strong>SC</strong>), International Symposium on High Performance Computer Architecture (<strong>HPCA</strong>), International Symposium on Field-Programmable Gate Arrays (<strong>FPGA</strong>), International Symposium on Field-Programmable Custom Computing Machines (<strong>FCCM</strong>), Design Automation Conference (<strong>DAC</strong>), International Conference on Computer‑Aided Design (<strong>ICCAD</strong>), IEEE Custom Integrated Circuits Conference (<strong>CICC</strong>), International Symposium on Low Power Electronics and Design (<strong>ISLPED</strong>), International Symposium on Microarchitecture (<strong>MICRO</strong>) (external), IEEE International Symposium on Circuits and Systems (<strong>ISCAS</strong>), International Electron Devices Meeting (<strong>IEDM</strong>), etc.. She served as the <em>advisory chair/general chair / technical chair / finance chair / publicity chair</em> for a premier industry memory conference – International Memory Workshop (<strong>IMW</strong>) and co-organized it with Intel/Micron/SK Hynix/CEA LETI to hold annual meetings with worldwide memory vendors. She is in the <em>Steering/Organizing Committee</em> for <strong>IMW</strong>, and serves as the <em>Publicity Chair</em> for <strong>FPGA&rsquo;20</strong>, <strong>FPGA&rsquo;19</strong> and <strong>ISLPED’18</strong>, the <em>Demo Chair</em> for <strong>MLSys&rsquo;20</strong>, the Best Paper committee <em>Co-Chair</em> for <strong>TRETS</strong>. She serves as Best Paper committee for several conferences including <strong>FCCM</strong> and <strong>CICC</strong>. She is an editor for Journal of Low Power Electronics (<strong>JOLPE</strong>), and associate editor for Transactions on Reconfigurable Technology and System (<strong>TRETS</strong>) and IEEE Computer Architecture Letters (<strong>CAL</strong>). She is serving at ACM SIGDA Technical Committee on FPGAs and Reconfigurable Computing (<strong>TC-FPGA</strong>).</p>


    <div class="row">

      
      <div class="col-md-5">
        <h3>Interests</h3>
        <ul class="ul-interests">
          
          <li>Computer Architecture</li>
          
          <li>Compiler</li>
          
          <li>Distributed Systems</li>
          
          <li>VLSI</li>
          
          <li>Machine Learning</li>
          
        </ul>
      </div>
      

      
      <div class="col-md-7">
        <h3>Education</h3>
        <ul class="ul-edu fa-ul">
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">PhD in Computer Engineering, 2009</p>
              <p class="institution">Purdue University</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">BSc in Electrical Engineering, 2004</p>
              <p class="institution">Shanghai Jiaotong University</p>
            </div>
          </li>
          
        </ul>
      </div>
      

    </div>
  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="people" class="home-section wg-people   "  >
    <div class="container">
      


<div class="row justify-content-center people-widget">
  
  <div class="col-md-12 section-heading">
    <h1>The Lab</h1>
    
  </div>
  

  

  
  <div class="col-md-12">
    <h2 class="mb-4">Principal Investigators</h2>
  </div>

  
  

  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      <a href="/authors/jing-li/"><img class="portrait" src="/authors/jing-li/avatar_hu0790a3ba0716acc2a92d0803f484434f_59031_150x150_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/authors/jing-li/">Jing Li</a></h2>
      <h3>Eduardo D. Glandt Faculty Fellow and Associate Professor</h3>
      <p class="people-interests">Computer Architecture, Compiler, Distributed Systems, VLSI, Machine Learning</p>
    </div>
  </div>

  
  
  <div class="col-md-12">
    <h2 class="mb-4">Researchers</h2>
  </div>

  
  
  
  <div class="col-md-12">
    <h2 class="mb-4">Grad Students</h2>
  </div>

  
  

  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      <a href="/authors/jialiang-zhang/"><img class="portrait" src="/authors/jialiang-zhang/avatar_hu494668576d3d69b1dde5be2bc8d73e7c_48310_150x150_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/authors/jialiang-zhang/">Jialiang Zhang</a></h2>
      <h3>PhD Candidate</h3>
      <p class="people-interests">FPGA based Accelerator, Wireless Communication Prototyping</p>
    </div>
  </div>

  

  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      <a href="/authors/yue-zha/"><img class="portrait" src="/authors/yue-zha/avatar_hu4e16e785e8846c3ff35f4dd91bca1b72_52661_150x150_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/authors/yue-zha/">Yue Zha</a></h2>
      <h3>PhD Candidate</h3>
      <p class="people-interests">Reconfigurable architecture, including both CMOS-based and RRAM-based, Processing-In-Memory architecture for big-data, System and compilation support for novel computing architecture</p>
    </div>
  </div>

  

  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      <a href="/authors/nick-beckwith/"><img class="portrait" src="/authors/nick-beckwith/avatar_hu1c32804c3ddc5ac08c22602c28ed6eda_249473_150x150_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/authors/nick-beckwith/">Nick Beckwith</a></h2>
      <h3>PhD Candidate</h3>
      <p class="people-interests">Frameworks for FPGA-accelerated system simulations, System support for Processing Near Memory, Applications and Systems for emerging memories</p>
    </div>
  </div>

  
  
  <div class="col-md-12">
    <h2 class="mb-4">Visitors</h2>
  </div>

  
  
  
  <div class="col-md-12">
    <h2 class="mb-4">Alumni</h2>
  </div>

  
  

  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      <a href="/authors/maxwell-strange/"><img class="portrait" src="/authors/maxwell-strange/avatar_huad02df39b17d30ae37e3c2a17dc647ba_383907_150x150_fill_q90_lanczos_center.JPG" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/authors/maxwell-strange/">Maxwell Strange</a></h2>
      <h3>Undergraduate Student (currently a PhD student at Stanford)</h3>
      <p class="people-interests">Software/Hardware Co-design, FPGA, Intelligent Instrumentation</p>
    </div>
  </div>

  

  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      <a href="/authors/huaye-li/"><img class="portrait" src="/authors/huaye-li/avatar_hu093b647f7ee52ab487eef7beec8fcd12_20016_150x150_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/authors/huaye-li/">Huaye Li</a></h2>
      <h3>MS Student (First employment - Apple Inc)</h3>
      <p class="people-interests">FPGA-based Hardware Acceleration for Priority Queue</p>
    </div>
  </div>

  
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  
    
    
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="research" class="home-section wg-blank   " style="padding: 20px 20px 20px 20px;" >
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      <h1>Research</h1>
      
      <p>At PennCIL, our research focuses on future systems in two general directions: 1) <strong>Augmenting computer systems with domain specific accelerators and emerging memories</strong>, an essential step towards next-generation systems. It requires modest system changes and has low deployment barrier but the performance gain might be potentially limited. 2) <strong>Rethinking computer systems with post-CMOS technology</strong>, a more aggressive approach in pushing innovations across the entire system stack. It could lead to dramatic improvement in performance but often requires more disruptive change in both hardware and software.</p>
<p><img src="/img/research-overview.png" alt="research overview" title="Title: Research Overview"></p>
<h1 id="augmenting-computer-systems-with-domain-specific-acceleratorsemerging-memories">Augmenting Computer Systems with Domain Specific Accelerators/Emerging Memories</h1>
<p>In this research theme, we organize our research around three high-level questions: 1) How to design domain specific accelerators for big data and machine learning applications? 2) What kind of system abstractions are needed to convert hardware specialization into direct benefits that can actually be realized by end-applications and “everyday” programmers? 3) How to effectively evaluate these cross-stack system methods with high fidelity, fairness, and performance? In this research, we aim to answer these questions via the following three paths: 1) architecture/algorithm co-design, 2) mechanisms and abstractions for virtualization, and 3) open-source system research infrastructure.</p>
<h2 id="architecturealgorithm-co-design">ARCHITECTURE/ALGORITHM CO-DESIGN</h2>
<h3 id="large-scale-graph-analytics">Large Scale Graph Analytics</h3>
<p>Extremely large, sparse graphs with billions of nodes and hundreds of billions of edges arise in many important problem domains ranging from social science, bioinformatics, to video content analysis and search engines. In response to the increasingly larger and more diverse graphs, and the critical need of analyzing them, we focus on <em>large scale graph analytics</em>, an essential class of big data analysis, to explore the comprehensive relationship among a vast collection of interconnected entities. However, it is challenging for existing computer systems to process the massive-scale real-world graphs, not only due to their large memory footprint, but also that most graph algorithms entail irregular memory access patterns and a low compute-to-memory access ratio.</p>
<p>In this research, we invented &ldquo;<em>degree-aware</em>&rdquo; hardware/software techniques to improve graph processing efficiency. Our research is built atop a key insight that we obtained from architecture-independent algorithm analysis, which has not been revealed in prior work. More specifically, we identified that a key challenge in processing massive-scale graphs is the redundant graph computations caused by the presence of high-degree vertices which not only increase the total amount of computations but also incur unnecessary random data access. To address this challenge, we developed variants of graph processing systems on an FPGA-HMC platform [<a href="/publication/zhang-2018-fpga">Zhang2018FPGA-Graph</a>, <a href="/publication/khoram-2018-fpga">Khoram2018FPGA</a>, <a href="/publication/zhang-2017-fpga-bfs">Zhang2017FPGA-BFS</a>]. For the first time, we leverage the inherent graph property i.e. vertex degree to co-optimize algorithm and hardware architecture. In particular, the unique contributions we made include two algorithm optimization techniques: degree-aware adjacency list reordering and degree-aware vertex index sorting. The former reduces the number of redundant graph computations, while the latter creates a strong correlation between vertex index and data access frequency, which can be effectively applied to guide the hardware design. Further, by leveraging the strong correlation between vertex index and data access frequency created by degree-aware vertex index sorting, we developed two platform-dependent hardware optimization techniques, namely degree-aware data placement and degree-aware adjacency list compression. These two techniques together substantially reduce the amount of external memory access. Finally, we completed the full system design on an FPGA-HMC platform to verify the effectiveness of these techniques. Our implementation achieved the highest performance (45.8 billion traversed edges per second) among existing FPGA-based graph processing systems and was ranked <strong>No. 1</strong> on <a href="http://graph500.org/?page_id=724">GreenGraph500 list</a>.</p>
<p>We have broken our previous record that we made at UW-madison in 2019 and created a new world record at Penn!
<img src="/img/Graph500_2021_6.png" alt="Green Graph500" title="Green Graph500"><em>Green Graph500: New ENIAD ranking (updated June 30, 2021)</em>
<img src="/img/GreenGraph500.png" alt="Green Graph500" title="Green Graph500"><em>Green Graph500: Old ranking (updated June 19, 2019)</em></p>
<p>More news can be found at <a href="https://penntoday.upenn.edu/news/penn-engineerings-eniad-sets-new-world-record-energy-efficient-supercomputing">Penn Today</a>, <a href="https://blog.seas.upenn.edu/penn-engineerings-eniad-sets-new-world-record-for-energy-efficient-supercomputing/">Penn Engineering Today</a> and <a href="http://news.tcfpga.org/2021/07/fpga-retake-top-spot-on-greengraph500/">TCFPGA News</a>.</p>
<h3 id="deep-leaning-and-ai">Deep Leaning and AI</h3>
<p>Deep neural networks (DNNs) deliver impressive results for a variety of challenging tasks in computer vision, speech recognition, and natural language processing, at the cost of higher computational complexity and larger model size. To reduce the load of taxing DNN infrastructures, a number of FPGA-based DNN accelerators have been proposed via new micro-architectures, data ow optimizations, or algorithmic transformation. Due to the extremely large design space, it is challenging to attain good insights on how to design optimal accelerators on a target FPGA.</p>
<p>In this research, we take an <em>alternative, and more principled approach to guide accelerator architecture design and optimization</em>. We borrow the insights from the roofline model and further improve it by taking both on-chip and off-chip memory bandwidth into consideration. We apply the model to quantify the difference between available resources provided by native hardware (FPGA devices) and actual resources demanded by the application (CNN classification kernel). To tackle the problem, we develop a number of hardware/software techniques and implement them on FPGA [<a href="/publication/zhang-2017-fpga-cnn">Zhang2017FPGA-CNN</a>]. The demonstrated accelerator was recognized as the highest performance and the most energy efficient accelerator for dense convolutional neural network (CNN) compared to the state-of-the-art FPGA-based designs.</p>
<h2 id="mechanisms-and-abstractions-for-virtualization-in-cloud">MECHANISMS AND ABSTRACTIONS FOR VIRTUALIZATION IN CLOUD</h2>
<p>While traditionally being used in embedded systems, custom silicon (e.g., FPGAs) has recently begun to make their way into data centers and the cloud (Amazon AWS EC2 F1 instances, Microsoft Brainwave, Google TPU etc.). While these programmable data-flow architectures provide the lucrative benefits of fine-grained parallelism and high flexibility to accelerate a wide spectrum of applications, system support for them in the context of multi-tenant cloud environment, however, is in its infancy and has two major limitations, 1) inefficient resource management due to the tight coupling between compilation and runtime management, and 2) high programming complexity when exploiting scale-out acceleration, for which the root cause is that <em>hardware resources are not virtualized</em>.</p>
<p>In this research, we take FPGA as a case study and develop a <em>full stack solution</em> that can address these limitations and thus, enable <em>virtualization of FPGA clusters in multi-tenant cloud computing environment</em>. Specifically, the key contribution is a new system abstraction that can effectively decouple the compilation and runtime resource management. It allows applications to be compiled offline onto the proposed abstraction and resource allocation to be dynamically determined at runtime. Moreover, it creates an illusion of a single/large virtual FPGA to users, thereby reducing the programming complexity and supporting scale-out acceleration. It also provides virtualization support for the peripheral components (e.g. on-board DRAM, Ethernet), as well as protection and isolation support to ensure a secure execution in multi-tenant cloud environment [<a href="/publication/zha-2020-asplos">Zha2020ASPLOS</a>].</p>
<h2 id="open-source-computer-system-infrastructure">OPEN SOURCE COMPUTER SYSTEM INFRASTRUCTURE</h2>
<p>Hardware-software co-design studies targeting next-generation computer systems that are equipped with emerging memories (HBM/HMC, NVM, etc.) are fundamentally hampered by a lack of scalable, performant and accurate simulation platform. Using software simulator is fundamentally bottlenecked by the low simulation speed and low fidelity, making it impractical to run realistic software stack. Such a challenge has limited effective cross-stack innovations (across computer architecture, OS, compiler, machine learning, and domain sciences). Past efforts have largely focused on simulation infrastructure for processor cores with highly simplified models of the memory subsystem. As a key contribution to the community (including SRC JUMP centers, broad academia and industry) to better drive cross-stack memory system research, we have been developing <strong>MEG</strong> [<a href="/publication/zhang-2019-fccm">Zhang2019FCCM</a>] – <em>an open source FPGA- based simulation platform that enables cycle-exact micro-architecture simulation for computer systems with a special focus on memory subsystem</em> (heterogeneous memory, near/in-memory acceleration). In MEG, we combine silicon- proven RTL design of RISC-V cores with configurable heterogeneous memory subsystems (HMC/HBM/NVM). It is capable of running realistic software stacks including booting Linux and comprehensive application software with high fidelity (cycle-exact microarchitectural models derived from synthesizable RTL), flexibility (modifiable to include custom RTL user IP and/or more abstract models), reproducibility, observability, target software support and performance. MEG can be an effective complement to previous <a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2006/EECS-2006-158.pdf">RAMP</a> and more recent <a href="https://fires.im/">Firesim</a> projects in covering memory space and a contribution to the open source <a href="https://riscv.org/">RISC-V</a> community.
<img src="/img/MEG_web.png" alt="MEG vs Existing infrastructure" title="MEG vs Existing infrastructure"></p>
<h1 id="rethinking-computer-systems-with-post-cmos-technology">Rethinking Computer Systems with Post-CMOS Technology</h1>
<p>Looking forward, we believe more disruptive approaches are needed to fundamentally re-think about how we build computers to address von Neumann bottleneck. We envision future computer chips will not solely be made by Si but rather can utilize and optimize the best of various post-CMOS technologies (including but not limited to novel 1D/2D devices, spintronics, resistive switching devices, quantum electrical/optical device, etc.), to effectively complement silicon CMOS in providing auxiliary/ancillary functions (or cost benefits) that otherwise cannot be easily achieved with silicon CMOS. In this research, we take emerging nonvolatile memory technology (e.g., RRAM) as a case study to showcase two <strong>general-purpose in-memory computing architectures</strong> based on two radically different non-von Neumann machine models. Note that these two architectures are fundamentally different from prior rich literature of applying memory array as domain-specific dot-product computing unit.</p>
<h2 id="liquid-silicon">Liquid Silicon</h2>
<p>Liquid Silicon (L-Si) is a general-purpose in-memory computing architecture with complete system support that addresses several key fundamental limitations of state-of-the-art reconfigurable data-flow architectures (including FPGA, TPU, CGRA, etc.) in supporting emerging machine learning and big data applications. As compared with most projects in literature which focus on part of the system stack, L-Si is a <em>full stack</em> solution that comprises architecture [<a href="/publication/zha-2018-fpga">Zha2018FPGA</a>], compiler [<a href="/publication/zha-2016-iccad">Zha2016ICCAD</a>], programming model and system integration [<a href="/publication/zha-2018-asplos">Zha2018ASPLOS</a>], with a real chip demonstration [<a href="/publication/zha-2019-vlsic">Zha2019VLSIC</a>]. The computing model of L-Si is radically different from state-of-the-art reconfigurable data-flow architectures. It maximally reuses the memory array itself (instead of placing computation units near the array) to perform a) heavy weight computation (<em>logic</em>), b) light weight computation(<em>search</em>), c) data storage (<em>memory</em>), and d) communication (<em>routing</em>), with minimal requirement in CMOS supporting circuitry, which can thus be further placed beneath the array. Therefore, it inherits the great benefits of semiconductor memory in integration density and cost, and offers orders of magnitude more parallel data processing capability in situ in the memory array than the best-known solution today. For the <strong>first time</strong>, it fundamentally blurs the boundary between computation and storage, by exploiting a continuum of general-purpose in-memory compute capabilities across the whole spectrum, from full memory to full computation, or intermediate states in between (partial memory and partial computation). Thus, it provides programmers (or compiler) more flexibility to customize hardware’s compute and memory resources to better match applications needs for higher performance and energy efficiency. We leverage such unique property and provide compiler support to facilitate the programming of applications written in high-level programming languages (e.g. OpenCL) and frameworks (e.g. TensorFlow, MapReduce) while fully exploiting the unique architectural capability of L-Si. We also provide scalable multi-context architectural support to minimize reconfiguration overhead for assisting virtualization when combined with our system stack.</p>
<p><img src="/img/LSi.png" alt="L-Si timeline" title="Timeline of Liquid Silicon project"><em>Timeline of L-Si project</em></p>
<p>To prove the feasibility of L-Si, we fabricated a test chip in 130 nm CMOS process with HfO2 RRAM – the <strong>first real-chip demonstration for general purpose in-memory computing using RRAM</strong>.</p>
<p><img src="/img/LSi-VLSI.png" alt="L-Si die photo" title="Die Photo and Chip Characteristics of L-Si"><em>Die Photo and Chip Characteristics of L-Si</em></p>
<p>With proposed system support, we evaluated a broad class of legacy and emerging machine learning workloads. Our measurement confirmed the chip operates reliably at low voltage of 650 mV when running these workloads. It achieves 60.9 TOPS/W in performing neural network inferences and 480 GOPS/W in performing high-dimensional similarity search (a key big data application) at nominal voltage supply of 1.2V, showing <strong>&gt; 3x</strong> and <strong>~100x</strong> power efficiency improvement over the state-of-the-art domain-specific CMOS-/RRAM-based accelerators without sacrificing the programmability. In addition, it outperforms the latest nonvolatile FPGA in energy efficiency by <strong>&gt; 3x</strong> in general compute-intensive applications. As L-Si is a fundamental new computing technology, moving further, we will explore how to scale it up to warehouse computers and scale it down to IoT devices by further specializing the software/hardware stacks.</p>
<p><img src="/img/LSi-VLSI-Results.png" alt="Comparing L-Si with State-of-the-Art" title="Comparing L-Si with State-of-the-Art"><em>Comparing L-Si with State-of-the-Art</em></p>
<h2 id="two-dimensional-associative-processor">Two-Dimensional Associative Processor</h2>
<p>The research project, titled &ldquo;<em>Associative In-Memory Graph Processing Paradigm: Towards Tera-TEPS Graph Traversal In a Box</em>&quot;, won the <strong>NSF CAREER Award</strong> in 2018. In this research, we developed a radically new computing paradigm, namely two-dimensional associative processing (2D AP) to further advance our previous FPGA-based graph processing architectures and fundamentally address their limitations. Mathematically, 2D AP is a new general-purpose computing model that exploits an extra dimension of parallelism (both intra-word and inter-word parallelism) to accelerate computation as compared with traditional AP which only exploit inter-word parallelism. It is particularly beneficial for massive-scale graph processing. For the first time, we provide a theoretical proof that 2D AP is inherently more efficient as measured by &ldquo;<em>architecturally determined complexity</em>&rdquo; in runtime/area/energy than both von Neumann architecture and traditional AP paradigm in performing graph computation. We also provide detailed micro-architectures and circuits to best implement the proposed computing model, with domain-special language support. A preliminary published version of 2D AP [<a href="/publication/khoram-2018-cal">Khoram2018CAL</a>] was recognized as <strong>best of CAL</strong> (IEEE Computer Architecture Letters) in 2018.</p>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="projects" class="home-section wg-portfolio   "  >
    <div class="container">
      










<div class="row">
  <div class="col-xs-12 col-md-4 section-heading">

    <h1>Projects</h1>
    

  </div>
  <div class="col-xs-12 col-md-8">



    

    

    <div class=" row js-layout-row ">
      

        
        
        

        
          


<div class="col-12 isotope-item js-id-liquid-siicon js-id-processing-in-memory js-id-machine-learning js-id-big-data js-id-general-purpose-computing js-id-reconfigurable">
  










  
  
  





  


<div class="media stream-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0" itemprop="name">
      <a href="/project/liquid-silicon/"  itemprop="url">Liquid Silicon</a>
    </h3>

    
    <div class="article-style" itemprop="articleBody">
      A general-purpose in-memory computing architecture that addresses several key fundamental limitations of state-of-the-art …
    </div>
    

    <div class="stream-meta article-metadata">

      

      
      <div itemprop="author">
        



  <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/yue-zha/">Yue Zha</a></span>

      </div>
      
    </div>

    
    <div class="btn-links">
      








  



















    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

</div>

        

      

        
        
        

        
          


<div class="col-12 isotope-item js-id-graph js-id-associative-processing js-id-general-purpose-computing">
  










  
  
  





  


<div class="media stream-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0" itemprop="name">
      <a href="/project/two-d-ap/"  itemprop="url">Two Dimensional Associative Processor (2D AP)</a>
    </h3>

    
    <div class="article-style" itemprop="articleBody">
      A radically new computing paradigm to further advance FPGA-based graph processing architectures and fundamentally address their …
    </div>
    

    <div class="stream-meta article-metadata">

      

      
      <div itemprop="author">
        



  <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/jing-li/">Jing Li</a></span>

      </div>
      
    </div>

    
    <div class="btn-links">
      








  



















    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

</div>

        

      

        
        
        

        
          


<div class="col-12 isotope-item js-id-open-source js-id-FPGA js-id-nonvolatile-memory js-id-RISC-V js-id-in-memory js-id-near-memory">
  










  
  
  





  


<div class="media stream-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0" itemprop="name">
      <a href="/project/meg/"  itemprop="url">MEG</a>
    </h3>

    
    <div class="article-style" itemprop="articleBody">
      An open source FPGA-based simulation platform for computer systems
    </div>
    

    <div class="stream-meta article-metadata">

      

      
      <div itemprop="author">
        



  <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/jialiang-zhang/">Jialiang Zhang</a></span>

      </div>
      
    </div>

    
    <div class="btn-links">
      








  



















    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

</div>

        

      

        
        
        

        
          


<div class="col-12 isotope-item js-id-virtualization js-id-cloud js-id-multi-tenant js-id-FPGA">
  










  
  
  





  


<div class="media stream-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0" itemprop="name">
      <a href="/project/virtualization/"  itemprop="url">Virtualization in Cloud</a>
    </h3>

    
    <div class="article-style" itemprop="articleBody">
      Virtualization of FPGA clusters in multi-tenant cloud computing environment
    </div>
    

    <div class="stream-meta article-metadata">

      

      
      <div itemprop="author">
        



  <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/yue-zha/">Yue Zha</a></span>

      </div>
      
    </div>

    
    <div class="btn-links">
      








  



















    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

</div>

        

      

        
        
        

        
          


<div class="col-12 isotope-item js-id-graph js-id-graph-analytics js-id-FPGA-HMC js-id-BFS">
  










  
  
  





  


<div class="media stream-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0" itemprop="name">
      <a href="/project/large-graph/"  itemprop="url">Large Scale Graph Analytics</a>
    </h3>

    
    <div class="article-style" itemprop="articleBody">
      <em>degree-aware</em> hardware/software techniques to improve graph processing efficiency.
    </div>
    

    <div class="stream-meta article-metadata">

      

      
      <div itemprop="author">
        



  <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/jialiang-zhang/">Jialiang Zhang</a></span>, <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/jing-li/">Jing Li</a></span>

      </div>
      
    </div>

    
    <div class="btn-links">
      








  



















    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/project/large-graph/" >
      <img src="/project/large-graph/featured_hua9d7e87dbf2f854d7e3995393ca30f7f_182863_150x0_resize_lanczos_2.png" itemprop="image">
    </a>
    
  </div>
</div>

</div>

        

      

        
        
        

        
          


<div class="col-12 isotope-item js-id-deep-learning js-id-DNN js-id-AI js-id-FPGA js-id-roofline-model js-id-convolutional-neural-network js-id-CNN">
  










  
  
  





  


<div class="media stream-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0" itemprop="name">
      <a href="/project/deep-learning/"  itemprop="url">Deep Learning and AI</a>
    </h3>

    
    <div class="article-style" itemprop="articleBody">
      An <em>alternative, and more principled approach</em> to guide accelerator architecture design and optimization
    </div>
    

    <div class="stream-meta article-metadata">

      

      
      <div itemprop="author">
        



  <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/jialiang-zhang/">Jialiang Zhang</a></span>

      </div>
      
    </div>

    
    <div class="btn-links">
      








  



















    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

</div>

        

      
    </div>

  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="publications" class="home-section wg-pages   "  >
    <div class="container">
      








  























  





  


<div class="row">
  <div class="col-12 col-lg-4 section-heading">
    <h1>Recent Publications</h1>
    
  </div>
  <div class="col-12 col-lg-8">

    <!-- raw HTML omitted -->


    
      
        <div class="pub-list-item" style="margin-bottom: 1rem" itemscope itemtype="http://schema.org/CreativeWork">
  <i class="far fa-file-alt pub-icon" aria-hidden="true"></i>

  
  

  <span itemprop="author" class="article-metadata li-cite-author">
    



  <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/yue-zha/">Yue Zha</a></span>, <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/jing-li/">Jing Li</a></span>

  </span>
  (2021).
  <a href="/publication/zha-2021-vital-isa/" itemprop="name">When Application-Specific ISA Meets FPGAs: A Multi-LayerVirtualization Framework for Heterogeneous Cloud FPGAs</a>.
  <em>the 25th ACM International Conference on Architectural Support for Programming Languages and Operating Systems</em>, ser. <strong>ASPLOS</strong> &lsquo;21, March, 2021.
  
  <p>








  









  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/virtualization/">
    Project
  </a>
  










</p>

  
  
</div>

      
    
      
        <div class="pub-list-item" style="margin-bottom: 1rem" itemscope itemtype="http://schema.org/CreativeWork">
  <i class="far fa-file-alt pub-icon" aria-hidden="true"></i>

  
  

  <span itemprop="author" class="article-metadata li-cite-author">
    



  <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/yue-zha/">Yue Zha</a></span>, <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/jing-li/">Jing Li</a></span>

  </span>
  (2020).
  <a href="/publication/zha-2020-hyper-ap/" itemprop="name">Hyper-AP: Enhancing Associative Processing Through A Full-Stack Optimization</a>.
  <em>2020 ACM/IEEE 45th Annual International Symposium on Computer Architecture</em>, ser. <strong>ISCA</strong> &lsquo;20, forthcoming, 2020.
  
  <p>








  





<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/zha-2020-hyper-ap/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/two-d-ap/">
    Project
  </a>
  










</p>

  
  
</div>

      
    
      
        <div class="pub-list-item" style="margin-bottom: 1rem" itemscope itemtype="http://schema.org/CreativeWork">
  <i class="far fa-file-alt pub-icon" aria-hidden="true"></i>

  
  

  <span itemprop="author" class="article-metadata li-cite-author">
    



  <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/yue-zha/">Yue Zha</a></span>, <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/jing-li/">Jing Li</a></span>

  </span>
  (2020).
  <a href="/publication/zha-2020-asplos/" itemprop="name">ViTAL: Virtualizing FPGAs in the Cloud</a>.
  <em>the 24th ACM International Conference on Architectural Support for Programming Languages and Operating Systems</em>, ser. <strong>ASPLOS</strong> &lsquo;20, March, 2020.
  
  <p>








  





<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/zha-2020-asplos/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/virtualization/">
    Project
  </a>
  







  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.youtube.com/watch?v=bGy4s4f72_Q" target="_blank" rel="noopener">
  Video
</a>



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://doi.org/10.1145/3373376.3378491" target="_blank" rel="noopener">
  DOI
</a>


</p>

  
  
</div>

      
    
      
        <div class="pub-list-item" style="margin-bottom: 1rem" itemscope itemtype="http://schema.org/CreativeWork">
  <i class="far fa-file-alt pub-icon" aria-hidden="true"></i>

  
  

  <span itemprop="author" class="article-metadata li-cite-author">
    



  <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/yue-zha/">Yue Zha</a></span>, <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/etienne-nowak/">Etienne Nowak</a></span>, <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/jing-li/">Jing Li</a></span>

  </span>
  (2020).
  <a href="/publication/zha-2020-jssc/" itemprop="name">Liquid Silicon: A Nonvolatile Fully Programmable Processing-In-Memory Processor with Monolithically Integrated ReRAM for Big Data/Machine Learning Applications (INVITED)</a>.
  <em>IEEE Journal of Solid-State Circuits (<strong>JSSC</strong>)</em>, 55(4), 908-919, 2020.
  
  <p>








  





<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/zha-2020-jssc/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/liquid-silicon/">
    Project
  </a>
  









<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://doi.org/10.1109/JSSC.2019.2963005" target="_blank" rel="noopener">
  DOI
</a>


</p>

  
  
</div>

      
    
      
        <div class="pub-list-item" style="margin-bottom: 1rem" itemscope itemtype="http://schema.org/CreativeWork">
  <i class="far fa-file-alt pub-icon" aria-hidden="true"></i>

  
  

  <span itemprop="author" class="article-metadata li-cite-author">
    



  <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/soroosh-khoram/">Soroosh Khoram</a></span>, <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/stephen-j-wright/">Stephen J Wright</a></span>, <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/jing-li/">Jing Li</a></span>

  </span>
  (2019).
  <a href="/publication/khoram-2019-interleaved/" itemprop="name">Interleaved Composite Quantization for High-Dimensional Similarity Search</a>.
  <em>arXiv preprint arXiv:1912.08756</em>.
  
  <p>








  





<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/khoram-2019-interleaved/cite.bib">
  Cite
</button>












  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/1912.08756" target="_blank" rel="noopener">
  Source Document
</a>



</p>

  
  
</div>

      
    

    
    <div class="see-all">
      <a href="/publication/">
        See all publications
        <i class="fas fa-angle-right"></i>
      </a>
    </div>
    

  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="talks" class="home-section wg-pages   "  >
    <div class="container">
      








  























  





  


<div class="row">
  <div class="col-12 col-lg-4 section-heading">
    <h1>Recent &amp; Upcoming Talks</h1>
    
  </div>
  <div class="col-12 col-lg-8">

    

    
      
        










  
  
  






<div class="media stream-item" itemscope itemtype="http://schema.org/Event">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0" itemprop="name">
      <a href="/talk/liquid-silicon-stanford-2019/"  itemprop="url">Liquid Silicon: A 10-year Journey Towards New Computing Paradigm</a>
    </h3>

    

    <div class="stream-meta article-metadata">

      
      <div>
        <span itemprop="startDate">
          Apr 3, 2019 4:00 PM &mdash; 5:00 PM
        </span>
        
        <span class="middot-divider"></span>
        <span itemprop="location">Dept. of Electrical Engineering, Stanford University</span>
        
      </div>
      

      
      <div itemprop="author">
        



  <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/jing-li/">Jing Li</a></span>

      </div>
      
    </div>

    
    <div class="btn-links">
      








  



















    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

      
    
      
        










  
  
  






<div class="media stream-item" itemscope itemtype="http://schema.org/Event">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0" itemprop="name">
      <a href="/talk/liquid-silicon-uchicago-2018/"  itemprop="url">Liquid Silicon: A New Computing Paradigm Enabled by Monolithic 3D Cross-point Memory</a>
    </h3>

    

    <div class="stream-meta article-metadata">

      
      <div>
        <span itemprop="startDate">
          Nov 6, 2018 3:30 PM &mdash; 4:30 PM
        </span>
        
        <span class="middot-divider"></span>
        <span itemprop="location">Dept. of Computer Science, University of Chicago</span>
        
      </div>
      

      
      <div itemprop="author">
        



  <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/jing-li/">Jing Li</a></span>

      </div>
      
    </div>

    
    <div class="btn-links">
      








  



















    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

      
    
      
        










  
  
  






<div class="media stream-item" itemscope itemtype="http://schema.org/Event">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0" itemprop="name">
      <a href="/talk/liquid-silicon-ucla-2018/"  itemprop="url">Liquid Silicon: A New Computing Paradigm Enabled by Monolithic 3D Cross-point Memory</a>
    </h3>

    

    <div class="stream-meta article-metadata">

      
      <div>
        <span itemprop="startDate">
          Oct 15, 2018 12:30 PM &mdash; 1:30 PM
        </span>
        
        <span class="middot-divider"></span>
        <span itemprop="location">Dept. of Electrical and Computer Engineering, University of California, Los Angeles (UCLA)</span>
        
      </div>
      

      
      <div itemprop="author">
        



  <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/jing-li/">Jing Li</a></span>

      </div>
      
    </div>

    
    <div class="btn-links">
      








  



















    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

      
    

    

  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  
    
    
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="sponsors" class="home-section wg-blank   " style="padding: 20px 0 20px 0;" >
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      <h1>Sponsors</h1>
      
      







  
  


<div class="gallery">

  
  
  
  

  
  
  
  
  
    
      
    
  
  <a data-fancybox="gallery-sponsors" data-caption="DARPA" href="/img/darpa.jpg">
    <img src="/img/darpa.jpg" alt="">
  </a>
  
  
  
  
    
      
    
  
  <a data-fancybox="gallery-sponsors" data-caption="NSF" href="/img/nsf.png">
    <img src="/img/nsf.png" alt="">
  </a>
  
  
  
  
    
      
    
  
  <a data-fancybox="gallery-sponsors" data-caption="SRC-JUMP" href="/img/src.png">
    <img src="/img/src.png" alt="">
  </a>
  
  
  
  
    
      
    
  
  <a data-fancybox="gallery-sponsors" data-caption="WARF" href="/img/warf.png">
    <img src="/img/warf.png" alt="">
  </a>
  
  
  
  
    
      
    
  
  <a data-fancybox="gallery-sponsors" data-caption="CEA-Leti" href="/img/cea-leti.jpg">
    <img src="/img/cea-leti.jpg" alt="">
  </a>
  
  
  
  
    
      
    
  
  <a data-fancybox="gallery-sponsors" data-caption="IBM" href="/img/ibm.png">
    <img src="/img/ibm.png" alt="">
  </a>
  
  
  
  
    
      
    
  
  <a data-fancybox="gallery-sponsors" data-caption="Intel" href="/img/intel.png">
    <img src="/img/intel.png" alt="">
  </a>
  
  
  
  
    
      
    
  
  <a data-fancybox="gallery-sponsors" data-caption="Micron" href="/img/micron.png">
    <img src="/img/micron.png" alt="">
  </a>
  
  
  
  
    
      
    
  
  <a data-fancybox="gallery-sponsors" data-caption="Nvdia" href="/img/nvidia.png">
    <img src="/img/nvidia.png" alt="">
  </a>
  
  
  
  
    
      
    
  
  <a data-fancybox="gallery-sponsors" data-caption="Panasonic" href="/img/panasonic.png">
    <img src="/img/panasonic.png" alt="">
  </a>
  
  
  
  
    
      
    
  
  <a data-fancybox="gallery-sponsors" data-caption="Xilinx" href="/img/xilinx.png">
    <img src="/img/xilinx.png" alt="">
  </a>
  
  
  
</div>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="contact" class="home-section wg-contact   "  >
    <div class="container">
      




<div class="row contact-widget">
  <div class="col-12 col-lg-4 section-heading">
    <h1>Contact &amp; Openings</h1>
    
  </div>
  <div class="col-12 col-lg-8">
    <h2 id="for-prospective-postdoctoral-researchers">For Prospective Postdoctoral Researchers</h2>
<p>We have openings for postdoctoral researchers in the areas of High Performance Computing, Complier, Distributed Systems, Data Science/Machine Learning, Computer Architecture, FPGA, and CAD. A PhD degree in Computer Engineering and Computer Science or other related field is required. You can contact Professor Li via email with your most up-to-date CV (including a complete publication list), at least two representative publications, a description of your research interests, and a list of references.</p>
<h2 id="for-prospective-phd-students">For Prospective PhD Students</h2>
<p>We welcome talented, hardworking, creative, self-motivated, and resilient PhD students who are excited about performing insightful cutting-edge research at the intersection of machine learning
and computer system to join our lab. A research vision on this can be found in the <a href="https://arxiv.org/abs/1904.03257">white paper</a>. Due to the interdisciplinary nature of our research, we are generally interested in students in the following areas: algorithm, compiler design, computer architecture, embedded systems, FPGA hands-on experience, VLSI and PCB board design. The additional <strong>preferred qualifications</strong> include: (1) <strong>High Performance Computing</strong>: Familiar with GPU-aware communication middleware: CUDA-aware MPI, NCCL, GPUDirect RDMA. (2) <strong>Compiler</strong>: a. Familiar with polyhedral optimizations and auto vectorization. b. Familiar with code generation, register allocation and instruction scheduling.</p>
<p>Please contact Professor Li via email with your most up-to-date CV (including GRE and TOEFL scores), one representative publication (if any), a description of your research interests, and a list of references. It is strongly recommended that students go over our recent <a href="#research">research</a> and <a href="/publication/">publications</a> first to find the best match.</p>
<h2 id="for-prospective-visiting-students-and-visiting-scholars">For Prospective Visiting Students and Visiting Scholars</h2>
<p>If you would like to be a visiting student or be a visiting scholar at PennCIL, please email Professor Li with your most up-to-date CV, a description of your research interests, and a list of references.</p>
<p><strong><em>Due to the large volume of emails, responses to the ones <em>without</em> sending complete materials as listed above cannot be guaranteed.</em></strong></p>


    

    <ul class="fa-ul" itemscope>

      
      <li>
        <i class="fa-li fas fa-envelope fa-2x" aria-hidden="true"></i>
        <span id="person-email" itemprop="email"><a href="mailto:janeli%20@%20seas.upenn.edu">janeli @ seas.upenn.edu</a></span>
      </li>
      

      

      
      <li>
        <i class="fa-li fas fa-map-marker fa-2x" aria-hidden="true"></i>
        <span id="person-address" itemprop="address">200 S. 33rd Street, Philadelphia, PA 19104, USA</span>
      </li>
      

      

      

      
      

    </ul>

    

  </div>
</div>

    </div>
  </section>



      

    
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/r.min.js"></script>
        
      

      
      
    

    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.16bbb3750feb7244c9bc409a5a4fe678.js"></script>

    






  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
