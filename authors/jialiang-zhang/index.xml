<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Penn Computational Intelligence Lab</title>
    <link>https://penn-cil.github.io/authors/jialiang-zhang/</link>
      <atom:link href="https://penn-cil.github.io/authors/jialiang-zhang/index.xml" rel="self" type="application/rss+xml" />
    <description>Penn Computational Intelligence Lab</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 11 Aug 2021 11:44:36 -0500</lastBuildDate>
    <image>
      <url>https://penn-cil.github.io/img/logo.png</url>
      <title>Penn Computational Intelligence Lab</title>
      <link>https://penn-cil.github.io/authors/jialiang-zhang/</link>
    </image>
    
    <item>
      <title>MEG</title>
      <link>https://penn-cil.github.io/project/meg/</link>
      <pubDate>Fri, 16 Aug 2019 15:58:48 -0500</pubDate>
      <guid>https://penn-cil.github.io/project/meg/</guid>
      <description>&lt;p&gt;Hardware-software co-design studies targeting next-generation computer systems that are equipped with emerging memories (HBM/HMC, NVM, etc.) are fundamentally hampered by a lack of scalable, performant and accurate simulation platform. Using software simulator is fundamentally bottlenecked by the low simulation speed and low fidelity, making it impractical to run realistic software stack. Such a challenge has limited effective cross-stack innovations (across computer architecture, OS, compiler, machine learning, and domain sciences). Past efforts have largely focused on simulation infrastructure for processor cores with highly simplified models of the memory subsystem. As a key contribution to the community (including SRC JUMP centers, broad academia and industry) to better drive cross-stack memory system research, we have been developing &lt;strong&gt;MEG&lt;/strong&gt; [&lt;a href=&#34;https://penn-cil.github.io/publication/zhang-2019-fccm&#34;&gt;Zhang2019FCCM&lt;/a&gt;] – &lt;em&gt;an open source FPGA- based simulation platform that enables cycle-exact micro-architecture simulation for computer systems with a special focus on memory subsystem&lt;/em&gt; (heterogeneous memory, near/in-memory acceleration). In MEG, we combine silicon- proven RTL design of RISC-V cores with configurable heterogeneous memory subsystems (HMC/HBM/NVM). It is capable of running realistic software stacks including booting Linux and comprehensive application software with high fidelity (cycle-exact microarchitectural models derived from synthesizable RTL), flexibility (modifiable to include custom RTL user IP and/or more abstract models), reproducibility, observability, target software support and performance. MEG can be an effective complement to previous &lt;a href=&#34;https://www2.eecs.berkeley.edu/Pubs/TechRpts/2006/EECS-2006-158.pdf&#34;&gt;RAMP&lt;/a&gt; and more recent &lt;a href=&#34;https://fires.im/&#34;&gt;Firesim&lt;/a&gt; projects in covering memory space and a contribution to the open source &lt;a href=&#34;https://riscv.org/&#34;&gt;RISC-V&lt;/a&gt; community.
&lt;img src=&#34;https://penn-cil.github.io/img/MEG_web.png&#34; alt=&#34;MEG vs Existing infrastructure&#34; title=&#34;MEG vs Existing infrastructure&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Large Scale Graph Analytics</title>
      <link>https://penn-cil.github.io/project/large-graph/</link>
      <pubDate>Fri, 16 Aug 2019 16:02:06 -0500</pubDate>
      <guid>https://penn-cil.github.io/project/large-graph/</guid>
      <description>&lt;p&gt;Extremely large, sparse graphs with billions of nodes and hundreds of billions of edges arise in many important problem domains ranging from social science, bioinformatics, to video content analysis and search engines. In response to the increasingly larger and more diverse graphs, and the critical need of analyzing them, we focus on &lt;em&gt;large scale graph analytics&lt;/em&gt;, an essential class of big data analysis, to explore the comprehensive relationship among a vast collection of interconnected entities. However, it is challenging for existing computer systems to process the massive-scale real-world graphs, not only due to their large memory footprint, but also that most graph algorithms entail irregular memory access patterns and a low compute-to-memory access ratio.&lt;/p&gt;
&lt;p&gt;In this research, we invented &amp;ldquo;&lt;em&gt;degree-aware&lt;/em&gt;&amp;rdquo; hardware/software techniques to improve graph processing efficiency. Our research is built atop a key insight that we obtained from architecture-independent algorithm analysis, which has not been revealed in prior work. More specifically, we identified that a key challenge in processing massive-scale graphs is the redundant graph computations caused by the presence of high-degree vertices which not only increase the total amount of computations but also incur unnecessary random data access. To address this challenge, we developed variants of graph processing systems on an FPGA-HMC platform [&lt;a href=&#34;https://penn-cil.github.io/publication/zhang-2018-fpga&#34;&gt;Zhang2018FPGA-Graph&lt;/a&gt;, &lt;a href=&#34;https://penn-cil.github.io/publication/khoram-2018-fpga&#34;&gt;Khoram2018FPGA&lt;/a&gt;, &lt;a href=&#34;https://penn-cil.github.io/publication/zhang-2017-fpga-bfs&#34;&gt;Zhang2017FPGA-BFS&lt;/a&gt;]. For the first time, we leverage the inherent graph property i.e. vertex degree to co-optimize algorithm and hardware architecture. In particular, the unique contributions we made include two algorithm optimization techniques: degree-aware adjacency list reordering and degree-aware vertex index sorting. The former reduces the number of redundant graph computations, while the latter creates a strong correlation between vertex index and data access frequency, which can be effectively applied to guide the hardware design. Further, by leveraging the strong correlation between vertex index and data access frequency created by degree-aware vertex index sorting, we developed two platform-dependent hardware optimization techniques, namely degree-aware data placement and degree-aware adjacency list compression. These two techniques together substantially reduce the amount of external memory access. Finally, we completed the full system design on an FPGA-HMC platform to verify the effectiveness of these techniques. Our implementation achieved the highest performance (45.8 billion traversed edges per second) among existing FPGA-based graph processing systems and was ranked &lt;strong&gt;No. 1&lt;/strong&gt; on &lt;a href=&#34;http://graph500.org/?page_id=724&#34;&gt;GreenGraph500 list&lt;/a&gt;.
&lt;img src=&#34;https://penn-cil.github.io/img/GreenGraph500.png&#34; alt=&#34;Green Graph500&#34; title=&#34;Green Graph500&#34;&gt;&lt;em&gt;Green Graph500 (updated June 19, 2019)&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning and AI</title>
      <link>https://penn-cil.github.io/project/deep-learning/</link>
      <pubDate>Fri, 16 Aug 2019 15:57:51 -0500</pubDate>
      <guid>https://penn-cil.github.io/project/deep-learning/</guid>
      <description>&lt;p&gt;Deep neural networks (DNNs) deliver impressive results for a variety of challenging tasks in computer vision, speech recognition, and natural language processing, at the cost of higher computational complexity and larger model size. To reduce the load of taxing DNN infrastructures, a number of FPGA-based DNN accelerators have been proposed via new micro-architectures, data ow optimizations, or algorithmic transformation. Due to the extremely large design space, it is challenging to attain good insights on how to design optimal accelerators on a target FPGA.&lt;/p&gt;
&lt;p&gt;In this research, we take an &lt;em&gt;alternative, and more principled approach to guide accelerator architecture design and optimization&lt;/em&gt;. We borrow the insights from the roofline model and further improve it by taking both on-chip and off-chip memory bandwidth into consideration. We apply the model to quantify the difference between available resources provided by native hardware (FPGA devices) and actual resources demanded by the application (CNN classification kernel). To tackle the problem, we develop a number of hardware/software techniques and implement them on FPGA [&lt;a href=&#34;https://penn-cil.github.io/publication/zhang-2017-fpga-cnn&#34;&gt;Zhang2017FPGA-CNN&lt;/a&gt;]. The demonstrated accelerator was recognized as the highest performance and the most energy efficient accelerator for dense convolutional neural network (CNN) compared to the state-of-the-art FPGA-based designs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ENIAD is on PennToday!</title>
      <link>https://penn-cil.github.io/post/penntoday2021/</link>
      <pubDate>Wed, 11 Aug 2021 11:44:36 -0500</pubDate>
      <guid>https://penn-cil.github.io/post/penntoday2021/</guid>
      <description>&lt;p&gt;ENIAD is on &lt;a href=&#34;https://penntoday.upenn.edu/news/penn-engineerings-eniad-sets-new-world-record-energy-efficient-supercomputing&#34;&gt;Penn Today&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;More news can be found at &lt;a href=&#34;https://blog.seas.upenn.edu/penn-engineerings-eniad-sets-new-world-record-for-energy-efficient-supercomputing/&#34;&gt;Penn Engineering Today&lt;/a&gt; and &lt;a href=&#34;http://news.tcfpga.org/2021/07/fpga-retake-top-spot-on-greengraph500/&#34;&gt;TCFPGA News&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Our supercomputer ranked No. 1 in the world!</title>
      <link>https://penn-cil.github.io/post/greengraph500-2021/</link>
      <pubDate>Mon, 05 Jul 2021 11:44:36 -0500</pubDate>
      <guid>https://penn-cil.github.io/post/greengraph500-2021/</guid>
      <description>&lt;p&gt;We have just broken another world record with our &lt;strong&gt;ENIAD&lt;/strong&gt; design. For this year&amp;rsquo;s Graph500, &lt;strong&gt;ENIAD&lt;/strong&gt; is the top-ranking supercomputer on the latest &lt;a href=&#34;http://graph500.org/?page_id=724&#34;&gt;GreenGraph500 list&lt;/a&gt;. We have broken our previous record that we made at UW-madison in 2019 and created a new world record at Penn!&lt;/p&gt;
&lt;p&gt;Supercomputers are the fastest high-performance computer systems available at any given time, allowing the large government or research organizations to tackle grand challenges (e.g., drug discovery for COVID-19, global climate simulation) that would be impossible with regular computers. Graph500 is the de facto standard to measure and quantitatively rank the performance and energy efficiency of supercomputers worldwide for running large graphs using a performance metric called MTEPS/W which represents million traversed edges per second per watt. More specifically, Green Graph500 is a list of the most energy efficient supercomputers in the world ranked by their energy efficiency from running the provided graph analytics applications. ENIAD achieved 6028.85 MTEPS/W, which outperformed &amp;ldquo;Tianhe-3&amp;rdquo; (4724.30 MTEPS/W) - the latest supercomputer in China and IBM supercomputer &amp;ldquo;Minsky&amp;rdquo;  (1165.71 MTEPS/W).&lt;/p&gt;
&lt;p&gt;The Graph500 competition is one important showcase for ENIAD but its capability extends to AI-enriched data analytics in general (e.g., cognitive search).&lt;/p&gt;
&lt;p&gt;More news can be found at &lt;a href=&#34;https://blog.seas.upenn.edu/penn-engineerings-eniad-sets-new-world-record-for-energy-efficient-supercomputing/&#34;&gt;Penn Engineering Today&lt;/a&gt; and &lt;a href=&#34;http://news.tcfpga.org/2021/07/fpga-retake-top-spot-on-greengraph500/&#34;&gt;TCFPGA News&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Our ENIAD (a successor to ENIAC) will be announced at Hotchips 2021</title>
      <link>https://penn-cil.github.io/post/hotchips2021/</link>
      <pubDate>Thu, 01 Jul 2021 19:28:42 -0400</pubDate>
      <guid>https://penn-cil.github.io/post/hotchips2021/</guid>
      <description>&lt;p&gt;We demostrated ENIAD – the first end-to-end computing infrastructure for future AI-enriched Big Data serving in real time at cloud scale. AI-enriched Big Data analytics is a fundamental technology to enable more powerful and intelligent cloud services such as cognitive search, as it has built-in AI capability that not only searches keywords but also can uncover contextual insights from ALL types of data sources (text, image, audio and video). However, the required large data volume, diverse indexing structure and complex dynamic data management pose severe challenges on contemporary datacenter infrastructures. ENIAD, named after ENIAC, was architected to address these critical challenges through a series of hardware and software innovations including near-data computation, reconfigurable computing and rapid/agile hardware deployment flow.&lt;/p&gt;
&lt;p&gt;At Penn, we have a long history in leading computing research. This year, we celebrated the 75th anniversary of &lt;a href=&#34;https://en.wikipedia.org/wiki/ENIAC&#34;&gt;ENIAC&lt;/a&gt;. ENIAD, as a salute to ENIAC, achieved the world-record performance compared to state-of-the-art CPU and GPU-based data center infrastructures. ENIAD will be announced at this year’s &lt;a href=&#34;https://hotchips.org/advance-program/&#34;&gt;Hot Chips&lt;/a&gt;(August 22 - 24, 2021).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Our graph analytics system ranked No. 1 on GreenGraph500</title>
      <link>https://penn-cil.github.io/post/greengraph5000/</link>
      <pubDate>Mon, 01 Jul 2019 11:44:36 -0500</pubDate>
      <guid>https://penn-cil.github.io/post/greengraph5000/</guid>
      <description>&lt;p&gt;Our FPGA-based scalable graph analytics system is ranked No. 1 on the latest &lt;a href=&#34;http://graph500.org/?page_id=724&#34;&gt;GreenGraph500 list&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MEG: A RISCV-based system simulation infrastructure for exploring memory optimization using FPGAs and Hybrid Memory Cube (Best Paper Nominee)</title>
      <link>https://penn-cil.github.io/publication/zhang-2019-fccm/</link>
      <pubDate>Sun, 28 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://penn-cil.github.io/publication/zhang-2019-fccm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our RISC-V paper got accepted at FCCM’19 and nominated Best Paper</title>
      <link>https://penn-cil.github.io/post/meg-fccm-2019/</link>
      <pubDate>Sun, 03 Mar 2019 16:54:36 -0500</pubDate>
      <guid>https://penn-cil.github.io/post/meg-fccm-2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Unleashing the Power of Soft Logic for Convolutional Neural Network Acceleration via Product Quantization (Poster)</title>
      <link>https://penn-cil.github.io/publication/zhang-2019-fpga/</link>
      <pubDate>Sun, 24 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://penn-cil.github.io/publication/zhang-2019-fpga/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Efficient Large-scale Approximate Nearest Neighbor Search on the OpenCL-FPGA</title>
      <link>https://penn-cil.github.io/publication/zhang-2018-cvpr/</link>
      <pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://penn-cil.github.io/publication/zhang-2018-cvpr/</guid>
      <description>&lt;p&gt;(Acceptance Rate: underline29%, 979 out of over 3300)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PQ-CNN: Accelerating Product Quantized Convolutional Neural Network (Poster)</title>
      <link>https://penn-cil.github.io/publication/zhang-2018-fccm/</link>
      <pubDate>Sun, 29 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://penn-cil.github.io/publication/zhang-2018-fccm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Accelerating  Graph  Analytics  By  Co-Optimizing  Storage  and  Access  on  an FPGA-HMC Platform</title>
      <link>https://penn-cil.github.io/publication/khoram-2018-fpga/</link>
      <pubDate>Sun, 25 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://penn-cil.github.io/publication/khoram-2018-fpga/</guid>
      <description>&lt;p&gt;(Acceptance Rate*: underline24%)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Degree-aware Hybrid Graph Traversal on FPGA-HMC Platform</title>
      <link>https://penn-cil.github.io/publication/zhang-2018-fpga/</link>
      <pubDate>Sun, 25 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://penn-cil.github.io/publication/zhang-2018-fpga/</guid>
      <description>&lt;p&gt;(Acceptance Rate*: underline24%)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Accelerating Large-Scale Graph Analytics with FPGA and HMC (Poster)</title>
      <link>https://penn-cil.github.io/publication/khoram-2017-fccm/</link>
      <pubDate>Sun, 30 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://penn-cil.github.io/publication/khoram-2017-fccm/</guid>
      <description>&lt;p&gt;Acceptance rate: underline25%, 32 out of 128&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Challenges and Opportunities: From Near-memory Computing to In-memory Computing (INVITED)</title>
      <link>https://penn-cil.github.io/publication/khoram-2017-ispd/</link>
      <pubDate>Sun, 19 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://penn-cil.github.io/publication/khoram-2017-ispd/</guid>
      <description>&lt;p&gt;(Acceptance Rate*: underline35%)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Mixed-Signal Data-Centric Reconfigurable Architecture Enabled by RRAM Technology (poster)</title>
      <link>https://penn-cil.github.io/publication/zha-2017-fpgaposter/</link>
      <pubDate>Wed, 22 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://penn-cil.github.io/publication/zha-2017-fpgaposter/</guid>
      <description>&lt;p&gt;(Acceptance Rate: underline25%, 25 out of 101)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Boosting the Performance of FPGA-based Graph Processor Using Hybrid Memory Cube: A Case for Breadth First Search</title>
      <link>https://penn-cil.github.io/publication/zhang-2017-fpga-bfs/</link>
      <pubDate>Wed, 22 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://penn-cil.github.io/publication/zhang-2017-fpga-bfs/</guid>
      <description>&lt;p&gt;(Acceptance Rate: underline25%, 25 out of 101)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Improving the Performance of OpenCL-based FPGA Accelerator for Convolutional Neural Network</title>
      <link>https://penn-cil.github.io/publication/zhang-2017-fpga-cnn/</link>
      <pubDate>Wed, 22 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://penn-cil.github.io/publication/zhang-2017-fpga-cnn/</guid>
      <description>&lt;p&gt;(Acceptance Rate: underline25%, 25 out of 101)&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
